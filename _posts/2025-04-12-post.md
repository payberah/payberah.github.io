---
title: 'Ethics Washing'
date: 2025-04-12
permalink: /posts/pos154/
---
<div align="justify" dir="ltr">

Ethics Washing! Do AI ethics toolkits actually protect society, or are they just feel-good mechanisms to check a box without changing the system? What are the consequences of integrating these toolkits? These and many other questions were the focus of the second session of our journal club, where we discussed the following two papers:<br>
<br>
1. Against Ethical AI, D. McMillan and B. Brown<br>
2. "Why do we do this?": Moral Stress and the Affective Experience of Ethics in Practice, S. Rattay et al.<br>
<br>
These two papers ask an important question: when we talk about "ethical AI", are we actually making things better or just pretending we are? "Against Ethical AI" takes a hard look at how ethics is used in the tech industry, showing that companies often adopt ethics guidelines not because they care but to protect their image or delay stronger regulation. The problem is that these efforts are often vague, symbolic, and disconnected from real-life consequences. They don't challenge the power structures or business interests behind the technology.<br>
<br>
The second paper, "Why Do We Do This?", explores what happens to people working within public tech teams who are genuinely trying to act ethically. While ethics tools can be helpful, they also create stress and confusion, especially when team members feel responsible for doing the right thing but lack the support or authority to actually make change. Some even burn out from the emotional toll. The paper calls this moral stress and emphasizes that ethics work requires more than good intentions; it needs real backing and care.<br>
<br>
Together, these papers show that doing ethics in AI isn't just about creating better principles. It's about asking harder questions: Who holds the power? Who gets to decide? And how do we support the people trying to make a difference?

</div>

